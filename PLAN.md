Use a single mono-repo. Keep “source of truth” in small, typed manifests. Generate tool-specific artifacts (Windsurf rules, Claude Code skills, MCP configs) from those manifests.

# Repository layout

```
ai-repo/
  README.md
  LICENSE
  .editorconfig
  .gitignore
  .pre-commit-config.yaml

  /docs/
    AGENTS.md              # autogenerated index of agents, skills, prompts
    STYLE_GUIDE.md         # how to write prompts, variables, eval rubric
    CHANGELOG.md

  /schemas/                # JSON Schemas for validation
    prompt.schema.json
    agent.schema.json
    rulepack.schema.json
    skill.schema.json
    eval.schema.json

  /rulepacks/              # reusable rulesets (code style, safety, tone)
    base.yml
    coding-kotlin.yml
    coding-python.yml
    reviewer.yml
    security.yml
    windsuf.defaults.yml   # repo-level defaults for tools

  /prompts/                # atomic prompts with metadata and variables
    refactor/
      extract-method.yml
      add-null-safety.yml
    docs/
      summarize-pr.yml
    qa/
      write-tests.yml
    shared/                # snippets included via {{ include }}
      constraints.md
      acceptance_criteria.md

  /agents/                 # tool-agnostic agent definitions
    code-reviewer.yml
    bug-fixer.yml
    tdd-navigator.yml
    kotlin-style-enforcer.yml

  /skills/                 # Claude Code skills (tool-agnostic source)
    run-detekt.yml
    run-ktlint.yml
    run-gradle-tests.yml
    search-repo.yml

  /mcp/                    # MCP servers and tool wiring
    servers/
      filesystem.yaml
      shell.yaml
      git.yaml
      http.yaml
    presets/
      base.tools.yaml
      secure.tools.yaml

  /adapters/               # generated or hand-tuned exports per tool
    windsuf/
      rules/               # build outputs from /rulepacks + /agents
      presets/
    claude-code/
      skills.json          # compiled from /skills
      prompts/             # compiled prompts
    cursor/
      recipes.json
    vscode/
      snippets/            # dev convenience
  /evals/
    datasets/
      bugfix_small.jsonl
      docstrings.jsonl
    suites/
      code-refactor.yml
      safety-guardrails.yml
    reports/               # CI artifacts
  /redteam/
    jailbreaks.txt
    unsafe-requests.jsonl
    code-injection-cases.md

  /scripts/
    build.ts               # compile manifests -> adapters
    validate.ts            # schema + lint
    eval.ts                # run promptfoo or custom harness
    diff.ts                # A/B compare outputs pre vs PR
    gen-docs.ts            # emit docs/AGENTS.md

  /config/
    providers.example.yml  # keys via env, non-secret defaults here
    budgets.yml            # per-suite token caps

  /packages/               # optional SDKs if you need code
    ts/
    py/
```

# File conventions

* All “source” files are YAML. Each has metadata.
* IDs are kebab-case and stable. Version with semver.

## Prompt manifest example (`/prompts/refactor/extract-method.yml`)

```yaml
id: refactor-extract-method
version: 1.3.0
description: Extract a pure function from a selected block.
tags: [kotlin, java, refactor]
variables:
  - name: code
    required: true
  - name: target_name
    required: false
includes:
  - ../shared/constraints.md
  - ../shared/acceptance_criteria.md
rules:
  - "Preserve behavior. No side effects."
  - "Add unit tests if none exist."
outputs:
  format: markdown
```

## Agent manifest example (`/agents/code-reviewer.yml`)

```yaml
id: code-reviewer
version: 2.1.0
purpose: Structured code review with actionable findings.
rulepacks:
  - base
  - reviewer
  - security
capabilities:
  - mcp:git
  - mcp:filesystem
defaults:
  temperature: 0.2
  style: terse
prompt:
  system: |
    You are a senior reviewer. Flag defects, risks, and tests to add.
  user_template: |
    Repo context: {{context}}
    Diff: {{diff}}
    Focus: {{focus?}}
```

## Rulepack example (`/rulepacks/coding-kotlin.yml`)

```yaml
id: coding-kotlin
extends: [base]
rules:
  - "Prefer immutable data classes."
  - "Use suspend + Structured Concurrency for async."
  - "Public APIs must be null-safe."
  - "Adopt Kotest + MockK or ScalaMock as per project policy."
```

## Claude Code skill source (`/skills/run-gradle-tests.yml`)

```yaml
id: run-gradle-tests
description: Run unit tests with Gradle
command:
  program: "./gradlew"
  args: ["test", "--info"]
constraints:
  - "Do not run if repo has no Gradle wrapper."
timeout_sec: 1800
```

# Build and validation

* `scripts/build.ts` composes:

  * Agents = base prompt + rulepacks + includes.
  * Adapters for tools. Example: emit Windsurf `rules/*.json`, Claude Code `skills.json`.
* `scripts/validate.ts` runs JSON Schema on all manifests and enforces:

  * unique IDs, semver present, referenced files exist.
  * no secrets in YAML (regex checks).
  * max token estimates per prompt.
* `scripts/gen-docs.ts` renders `docs/AGENTS.md` from manifests.

# Evals

* Keep golden tasks in `/evals/datasets/*.jsonl`.
* Define suites mapping prompts/agents → datasets and success checks.
* Use `promptfoo` or a simple custom harness.
* Gate PRs on:

  * deterministic cases equal or better,
  * safety doesn’t regress,
  * token cost within `/config/budgets.yml`.

Example suite (`/evals/suites/code-refactor.yml`)

```yaml
suite: code-refactor
targets:
  - prompt: refactor-extract-method
    dataset: datasets/bugfix_small.jsonl
checks:
  - name: builds
    cmd: "./gradlew build"
  - name: tests-pass
    cmd: "./gradlew test"
  - name: regex-no-todo
    pattern: "(?i)TODO|FIXME"
budgets:
  max_tokens: 200000
```

# CI workflow

* Pre-commit: YAML lint, schema validate, link check.
* CI stages:

  1. `validate` → fail fast.
  2. `build` → generate adapters.
  3. `eval` → run suites with tight budgets.
  4. `diff` → show A/B output changes; attach HTML report in `/evals/reports`.
* Block merge if any suite regresses or budgets exceeded.

# Working model

1. Add or change a rule/prompt only in source YAML.
2. Run `npm run validate && npm run build`.
3. Run focused eval: `npm run eval -- --suite code-refactor`.
4. Open PR with:

   * change summary,
   * before/after samples,
   * eval deltas,
   * token cost delta.
5. On merge, publish adapters as a versioned artifact:

   * Tag repo `vX.Y.Z`.
   * Optionally publish `/adapters/*` as NPM or a GitHub Release for easy consumption in tools.

# Consumption patterns

* **Windsurf/Cursor**: point tool settings to `/adapters/windsuf/presets/*.json`. Keep them small and composable.
* **Claude Code**: import generated `skills.json` and compiled prompts. Skills reference MCP tools by ID.
* **MCP**: enable only `presets/secure.tools.yaml` on corp machines. Keep `shell` disabled by default.

# Secrets and environments

* No secrets in repo. Use `${ENV_VAR}` placeholders.
* Provide `/config/providers.example.yml`. Load real keys from CI secrets or local `.env`.
* Keep dev vs prod toggles in agent defaults (temperature, model, safety).

# Versioning and change control

* Semver for each manifest.
* Changelog entries auto-generated from commit messages with conventional commits.
* Deprecate by keeping old IDs and mapping them to new ones in `adapters/compat.json`.

# Guardrails and red-teaming

* Store jailbreaks and unsafe prompts in `/redteam/`.
* Add a safety eval suite. Fail CI on unsafe responses or policy violations to known probes.

# What you might not realize you need

* **Token cost tracking** per prompt and per suite. Prevent silent bloat.
* **Prompt lint rules**: ban vague verbs, cap sentence length in system prompts, enforce variable presence.
* **Golden “negative” tests**: inputs where the correct action is refusal.
* **Doc generator** for AGENTS.md so humans use the latest rules.
* **Adapter diff tests** so generated tool configs stay stable across builds.

# Minimal command set (npm scripts)

```json
{
  "scripts": {
    "validate": "tsx scripts/validate.ts",
    "build": "tsx scripts/build.ts",
    "eval": "tsx scripts/eval.ts",
    "diff": "tsx scripts/diff.ts",
    "docs": "tsx scripts/gen-docs.ts",
    "ci": "npm run validate && npm run build && npm run eval && npm run docs"
  }
}
```

# How to work with it day-to-day

* Create or edit only YAML in `/prompts`, `/agents`, `/rulepacks`, `/skills`.
* Run `npm run ci` locally before a PR.
* Review the generated `docs/AGENTS.md` and the eval report.
* Ship only the `/adapters/*` outputs to tools. Never edit them by hand.
* Keep each change small and paired with an eval update.

