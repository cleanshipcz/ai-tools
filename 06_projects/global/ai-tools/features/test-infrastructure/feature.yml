id: test-infrastructure
version: 1.0.0
name: "Automated Test Infrastructure"
description: "Automated testing system for validating internal functionality and generated outputs with regression test coverage"

# What this feature is about
context:
  overview: |
    Set up automated testing infrastructure for the ai-tools repository.
    Tests should validate internal functionality (manifest parsing, validation, generation logic)
    and generated outputs (prompts, agents, recipes) across all supported tools.
    All test outputs should go to a gitignored directory and be cleaned up after test runs.
    This serves as both feature validation and regression test suite for future changes.

  dependencies:
    - "Test framework (agent will select best practice)"
    - "Existing build system (11_scripts/)"

# Key files for this feature
files:
  patterns:
    - "11_scripts/**/*.test.ts"
    - "11_scripts/__tests__/**/*"
    - ".output-test/**/*"

# What success looks like
conventions:
  - "Test files mirror source structure: 11_scripts/foo.ts â†’ 11_scripts/foo.test.ts"
  - "Use .output-test/ directory for generated test outputs (gitignored)"
  - "Clean up test artifacts after test runs"
  - "Tests should be fast and deterministic (no flaky tests)"
  - "Avoid manual testing - automate everything"

# Bind to feature-delivery recipe
recipe:
  id: feature-delivery
  context:
    feature_description: |
      Implement automated test infrastructure for the ai-tools repository.

      Requirements:
      - Select and set up appropriate test framework (best practice for TypeScript/Node.js)
      - Create test structure mirroring source files (11_scripts/*.test.ts)
      - Test internal functionality:
        - Manifest validation and parsing
        - Schema validation logic
        - Build and generation workflows
      - Test output generation:
        - Generate outputs to .output-test/ directory
        - Validate generated files for all tools (github-copilot, windsurf, claude-code, cursor)
        - Validate output structure and content
      - Set up regression tests for known issues (backticks, date formats, etc.)
      - Configure CI/CD integration
      - Add npm test script
      - Clean up test outputs after test runs

    acceptance_criteria: |
      - Test framework installed and configured
      - Tests run via: npm test
      - Tests run automatically in CI/CD
      - Target: 80% code coverage
      - Test outputs generated to .output-test/ (gitignored)
      - Test outputs cleaned up after runs
      - All tests pass
      - Tests complete in reasonable time (under 30s)
      - No flaky tests
      - Regression tests for known issues included

# Metadata
metadata:
  status: draft
  owner: ai-tools-core
  created: 2025-11-16
  updated: 2025-11-16
  tags:
    - testing
    - infrastructure
    - automation
    - quality-assurance
